{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 datetime    open    high     low   close   volume  \\\n0     2023-12-04 10:40:00  187.85  187.90  187.80  187.84   119927   \n1     2023-12-04 10:41:00  187.85  187.90  187.77  187.87   128851   \n2     2023-12-04 10:42:00  187.86  188.02  187.84  188.00   107009   \n3     2023-12-04 10:43:00  187.99  188.14  187.98  188.10    96643   \n4     2023-12-04 10:44:00  188.12  188.14  188.02  188.02   123641   \n...                   ...     ...     ...     ...     ...      ...   \n4995  2023-12-20 15:55:00  195.50  195.50  195.21  195.26   497956   \n4996  2023-12-20 15:56:00  195.26  195.34  195.21  195.23   309867   \n4997  2023-12-20 15:57:00  195.22  195.28  195.06  195.07   446759   \n4998  2023-12-20 15:58:00  195.07  195.24  195.06  195.12   540699   \n4999  2023-12-20 15:59:00  195.12  195.23  194.84  194.84  1291086   \n\n      open-trend  open-change  high-trend  high-change  ...  close-change  \\\n0              1          NaN           1          NaN  ...           NaN   \n1              1          NaN           1          NaN  ...           NaN   \n2              1          NaN           1          NaN  ...           NaN   \n3              1          NaN           1          NaN  ...           NaN   \n4              1          NaN           1          NaN  ...           NaN   \n...          ...          ...         ...          ...  ...           ...   \n4995           1         0.01           0        -0.05  ...         -0.26   \n4996           0        -0.26           0        -0.20  ...         -0.20   \n4997           0        -0.21           0        -0.23  ...         -0.41   \n4998           0        -0.42           0        -0.29  ...         -0.30   \n4999           0        -0.31           0        -0.34  ...         -0.67   \n\n      volume-trend  volume-change  percent_b  macd  macd_signal  macd_hist  \\\n0                1            NaN       0.22 -0.32        -0.33       0.01   \n1                1            NaN       0.25 -0.31        -0.33       0.01   \n2                1            NaN       0.39 -0.29        -0.32       0.03   \n3                1            NaN       0.54 -0.26        -0.31       0.05   \n4                1            NaN       0.46 -0.24        -0.29       0.05   \n...            ...            ...        ...   ...          ...        ...   \n4995             1       342059.0       0.22 -0.00        -0.01       0.00   \n4996             0       217634.0       0.14 -0.02        -0.01      -0.01   \n4997             1       331992.0      -0.10 -0.05        -0.02      -0.03   \n4998             1       420099.0       0.03 -0.07        -0.03      -0.04   \n4999             0      1141090.0      -0.21 -0.10        -0.04      -0.06   \n\n        adx     ema    rsi  \n0     53.77  187.97  23.57  \n1     54.43  187.95  25.75  \n2     53.50  187.96  34.47  \n3     51.37  187.99  40.29  \n4     49.40  187.99  37.60  \n...     ...     ...    ...  \n4995  14.89  195.46  40.40  \n4996  15.49  195.42  39.28  \n4997  16.89  195.35  34.04  \n4998  18.19  195.30  37.11  \n4999  20.37  195.21  29.41  \n\n[5000 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>open-trend</th>\n      <th>open-change</th>\n      <th>high-trend</th>\n      <th>high-change</th>\n      <th>...</th>\n      <th>close-change</th>\n      <th>volume-trend</th>\n      <th>volume-change</th>\n      <th>percent_b</th>\n      <th>macd</th>\n      <th>macd_signal</th>\n      <th>macd_hist</th>\n      <th>adx</th>\n      <th>ema</th>\n      <th>rsi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-12-04 10:40:00</td>\n      <td>187.85</td>\n      <td>187.90</td>\n      <td>187.80</td>\n      <td>187.84</td>\n      <td>119927</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.22</td>\n      <td>-0.32</td>\n      <td>-0.33</td>\n      <td>0.01</td>\n      <td>53.77</td>\n      <td>187.97</td>\n      <td>23.57</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-12-04 10:41:00</td>\n      <td>187.85</td>\n      <td>187.90</td>\n      <td>187.77</td>\n      <td>187.87</td>\n      <td>128851</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.25</td>\n      <td>-0.31</td>\n      <td>-0.33</td>\n      <td>0.01</td>\n      <td>54.43</td>\n      <td>187.95</td>\n      <td>25.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-12-04 10:42:00</td>\n      <td>187.86</td>\n      <td>188.02</td>\n      <td>187.84</td>\n      <td>188.00</td>\n      <td>107009</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.39</td>\n      <td>-0.29</td>\n      <td>-0.32</td>\n      <td>0.03</td>\n      <td>53.50</td>\n      <td>187.96</td>\n      <td>34.47</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-12-04 10:43:00</td>\n      <td>187.99</td>\n      <td>188.14</td>\n      <td>187.98</td>\n      <td>188.10</td>\n      <td>96643</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.54</td>\n      <td>-0.26</td>\n      <td>-0.31</td>\n      <td>0.05</td>\n      <td>51.37</td>\n      <td>187.99</td>\n      <td>40.29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-12-04 10:44:00</td>\n      <td>188.12</td>\n      <td>188.14</td>\n      <td>188.02</td>\n      <td>188.02</td>\n      <td>123641</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.46</td>\n      <td>-0.24</td>\n      <td>-0.29</td>\n      <td>0.05</td>\n      <td>49.40</td>\n      <td>187.99</td>\n      <td>37.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>2023-12-20 15:55:00</td>\n      <td>195.50</td>\n      <td>195.50</td>\n      <td>195.21</td>\n      <td>195.26</td>\n      <td>497956</td>\n      <td>1</td>\n      <td>0.01</td>\n      <td>0</td>\n      <td>-0.05</td>\n      <td>...</td>\n      <td>-0.26</td>\n      <td>1</td>\n      <td>342059.0</td>\n      <td>0.22</td>\n      <td>-0.00</td>\n      <td>-0.01</td>\n      <td>0.00</td>\n      <td>14.89</td>\n      <td>195.46</td>\n      <td>40.40</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>2023-12-20 15:56:00</td>\n      <td>195.26</td>\n      <td>195.34</td>\n      <td>195.21</td>\n      <td>195.23</td>\n      <td>309867</td>\n      <td>0</td>\n      <td>-0.26</td>\n      <td>0</td>\n      <td>-0.20</td>\n      <td>...</td>\n      <td>-0.20</td>\n      <td>0</td>\n      <td>217634.0</td>\n      <td>0.14</td>\n      <td>-0.02</td>\n      <td>-0.01</td>\n      <td>-0.01</td>\n      <td>15.49</td>\n      <td>195.42</td>\n      <td>39.28</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>2023-12-20 15:57:00</td>\n      <td>195.22</td>\n      <td>195.28</td>\n      <td>195.06</td>\n      <td>195.07</td>\n      <td>446759</td>\n      <td>0</td>\n      <td>-0.21</td>\n      <td>0</td>\n      <td>-0.23</td>\n      <td>...</td>\n      <td>-0.41</td>\n      <td>1</td>\n      <td>331992.0</td>\n      <td>-0.10</td>\n      <td>-0.05</td>\n      <td>-0.02</td>\n      <td>-0.03</td>\n      <td>16.89</td>\n      <td>195.35</td>\n      <td>34.04</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>2023-12-20 15:58:00</td>\n      <td>195.07</td>\n      <td>195.24</td>\n      <td>195.06</td>\n      <td>195.12</td>\n      <td>540699</td>\n      <td>0</td>\n      <td>-0.42</td>\n      <td>0</td>\n      <td>-0.29</td>\n      <td>...</td>\n      <td>-0.30</td>\n      <td>1</td>\n      <td>420099.0</td>\n      <td>0.03</td>\n      <td>-0.07</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n      <td>18.19</td>\n      <td>195.30</td>\n      <td>37.11</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>2023-12-20 15:59:00</td>\n      <td>195.12</td>\n      <td>195.23</td>\n      <td>194.84</td>\n      <td>194.84</td>\n      <td>1291086</td>\n      <td>0</td>\n      <td>-0.31</td>\n      <td>0</td>\n      <td>-0.34</td>\n      <td>...</td>\n      <td>-0.67</td>\n      <td>0</td>\n      <td>1141090.0</td>\n      <td>-0.21</td>\n      <td>-0.10</td>\n      <td>-0.04</td>\n      <td>-0.06</td>\n      <td>20.37</td>\n      <td>195.21</td>\n      <td>29.41</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows Ã— 23 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "file_path = \"data/AAPL_time_series.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\mohae\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mc:\\users\\mohae\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mc:\\users\\mohae\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m     time_series_target\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(time_series_target)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m time_series_batch, time_series_target\n\u001B[1;32m---> 15\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[43mget_recent_time_series_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03mX is a list with contains (len(df) - seq_length) entries. The first entry is a list of the first seq_length rows of df. X[index][-1] gives you the (index + seq_length)-th row of df.\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;124;03my is a list that contains (len(df) - seq_length) entries. The first entry is the \"target\" column of the seq_length row. X[index][-1][-1] and y[index] are the same \"target\" value.\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;124;03mIf df has 5000 entries, X.shape y.shape will give you: ((4980, 10, 25), (4980,))\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     22\u001B[0m X\u001B[38;5;241m.\u001B[39mshape, y\u001B[38;5;241m.\u001B[39mshape\n",
      "Cell \u001B[1;32mIn[49], line 9\u001B[0m, in \u001B[0;36mget_recent_time_series_batch\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df) \u001B[38;5;241m-\u001B[39m seq_length):\n\u001B[0;32m      8\u001B[0m     time_series_batch\u001B[38;5;241m.\u001B[39mappend(df\u001B[38;5;241m.\u001B[39miloc[row:row \u001B[38;5;241m+\u001B[39m seq_length]\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m----> 9\u001B[0m     time_series_target\u001B[38;5;241m.\u001B[39mappend(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget_column_name\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39miloc[row \u001B[38;5;241m+\u001B[39m seq_length \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m     11\u001B[0m time_series_batch \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(time_series_batch)\n\u001B[0;32m     12\u001B[0m time_series_target\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(time_series_target)\n",
      "File \u001B[1;32mc:\\users\\mohae\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mc:\\users\\mohae\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'target'"
     ]
    }
   ],
   "source": [
    "def get_recent_time_series_batch() -> tuple:\n",
    "    seq_length: int = 10\n",
    "    target_column_name: str = \"target\"\n",
    "    time_series_batch = []\n",
    "    time_series_target = []\n",
    "\n",
    "    for row in range(len(df) - seq_length):\n",
    "        time_series_batch.append(df.iloc[row:row + seq_length].values)\n",
    "        time_series_target.append(df[target_column_name].iloc[row + seq_length - 1])\n",
    "\n",
    "    time_series_batch = np.array(time_series_batch)\n",
    "    time_series_target= np.array(time_series_target)\n",
    "    return time_series_batch, time_series_target\n",
    "\n",
    "X, y = get_recent_time_series_batch()\n",
    "\n",
    "\"\"\"\n",
    "X is a list with contains (len(df) - seq_length) entries. The first entry is a list of the first seq_length rows of df. X[index][-1] gives you the (index + seq_length)-th row of df.\n",
    "y is a list that contains (len(df) - seq_length) entries. The first entry is the \"target\" column of the seq_length row. X[index][-1][-1] and y[index] are the same \"target\" value.\n",
    "If df has 5000 entries, X.shape y.shape will give you: ((4980, 10, 25), (4980,))\n",
    "\"\"\"\n",
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into training and temporary sets\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "# Further split the temporary set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=test_size, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Print the shapes of the sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.layers import LSTM, Dropout, Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(history.history['accuracy'][1:], label='Training Accuracy', color=\"green\")\n",
    "ax1.plot(history.history['val_accuracy'][1:], label='Validation Accuracy', color=\"#ff4d4d\")\n",
    "\n",
    "ax1.set_title('Accuracy Plot')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['loss'][1:], label='Training Loss', color=\"green\")\n",
    "ax2.plot(history.history['val_loss'][1:], label='Validation Loss', color=\"#ff4d4d\")\n",
    "\n",
    "ax2.set_title('Accuracy Plot')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "y_actual = y_test\n",
    "results_df = pd.DataFrame({'Actual': y_actual, 'Predicted': y_pred.flatten(), 'Predicted_Prob': y_pred_prob.flatten()})\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "group_names = [\"True Neg.\",\"False Pos.\",\"False Neg.\",\"True Pos.\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
